{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import tensorflow.compat.v1 as tf\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k, reciprocal_rank\n",
    "from lightfm import cross_validation\n",
    "import csv\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the LightFM library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LightFM](https://making.lyst.com/lightfm/docs/index.html) is a Python implementation of a number of popular recommendation algorithms for both implicit and explicit feedback. It also makes it possible to incorporate both item and user metadata into the traditional matrix factorization algorithms. It represents each user and item as the sum of the latent representations of their features, thus allowing recommendations to generalise to new items (via item features) and to new users (via user features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the LightFM requires their own Object Class, we would need to retrive the data in the form of DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return csv.DictReader(\n",
    "            (x for x in open('Data/Cleaned_Data/book_user_explicit_rating_cleaned.csv','r'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare our interactions matrix with LightFM library\n",
    "\n",
    "Thanks to the flexibility of LightFM, it will automatically become a Hybrid recommender algorithm if we includes item or user features. On the otherhand, if we do not specify item features or user features, it will use a basic CF matrix factorizatioon algorithm.\n",
    "\n",
    "In this project, we will include the item feature `Book_Author` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fit(users=(x['User_ID'] for x in get_data()),\n",
    "            items=(x['Unique_ISBN'] for x in get_data()),\n",
    "            item_features=(x['Book_Author'] for x in get_data())\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build interaction matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 17511, num_items 13607.\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('Num users: {}, num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions, weights) = dataset.build_interactions(((x['User_ID'], x['Unique_ISBN'])\n",
    "                                                      for x in get_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<17511x13607 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 151324 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<13607x18702 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 27407 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "item_features = dataset.build_item_features(((x['Unique_ISBN'], [x['Book_Author']])\n",
    "                                              for x in get_data()))\n",
    "print(repr(item_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions, test_interactions = cross_validation.random_train_test_split(interactions, random_state=np.random.RandomState(seed=11232))\n",
    "\n",
    "train_weights, test_weights = cross_validation.random_train_test_split(weights, random_state=np.random.RandomState(seed=11232))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform random search for our hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def sample_hyperparameters():\n",
    "    \"\"\"\n",
    "    Yield possible hyperparameter choices.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        yield {\n",
    "            \"no_components\": np.random.randint(16, 64),\n",
    "            \"loss\": np.random.choice([\"warp\",\"bpr\"]),\n",
    "            \"learning_rate\": np.random.exponential(0.05),\n",
    "            \"num_epochs\": np.random.randint(5, 50),\n",
    "            \"random_state\":np.random.RandomState(seed=11232)\n",
    "        }\n",
    "\n",
    "\n",
    "def random_search(train, test, num_samples=10):\n",
    "    \"\"\"\n",
    "    Sample random hyperparameters, fit a LightFM model, and evaluate it\n",
    "    on the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    train: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Training data.\n",
    "    test: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Test data.\n",
    "    num_samples: int, optional\n",
    "        Number of hyperparameter choices to evaluate.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    generator of (auc_score, hyperparameter dict, fitted model)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for hyperparams in itertools.islice(sample_hyperparameters(), num_samples):\n",
    "        num_epochs = hyperparams.pop(\"num_epochs\")\n",
    "\n",
    "        model_tune = LightFM(**hyperparams)\n",
    "        model_tune.fit(interactions=train, epochs=num_epochs, item_features=item_features,sample_weight=train_weights)\n",
    "\n",
    "        score = auc_score(model_tune, train, item_features=item_features).mean()\n",
    "        auc_test = auc_score(model_tune, test, item_features=item_features).mean()\n",
    "\n",
    "        hyperparams[\"num_epochs\"] = num_epochs\n",
    "\n",
    "        yield (score, auc_test, hyperparams, model_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.9985889792442322 at {'no_components': 55, 'loss': 'warp', 'learning_rate': 0.09824398527330847, 'random_state': RandomState(MT19937) at 0x7FAB29861440, 'num_epochs': 35}\n",
      "Best test 0.7623966336250305 at {'no_components': 55, 'loss': 'warp', 'learning_rate': 0.09824398527330847, 'random_state': RandomState(MT19937) at 0x7FAB29861440, 'num_epochs': 35}\n"
     ]
    }
   ],
   "source": [
    "(score, auc_test, hyperparams, model_tune) = max(random_search(train_interactions, test_interactions), key=lambda x: x[0])\n",
    "\n",
    "print(\"Best score {} at {}\".format(score, hyperparams))\n",
    "print(\"Best test {} at {}\".format(auc_test, hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The results of test and train score above depict that our model is prone to overfitting. Therefore, we will use a lower number of components and learning rate with a lower number of epoch to minimize the difference between AUC score of train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [00:03<00:00,  2.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fab2a7c7910>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = LightFM(loss='warp',learning_rate=0.01824398527330847,no_components=45)\n",
    "best_model.fit(\n",
    "    interactions=train_interactions,\n",
    "    item_features=item_features, sample_weight=train_weights,\n",
    "    epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (AUC score, Precision, and Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86399215\n",
      "0.77531123\n"
     ]
    }
   ],
   "source": [
    "auc_train = auc_score( \n",
    "        best_model, train_interactions, \n",
    "        item_features=item_features).mean()\n",
    "auc_test = auc_score( \n",
    "        best_model, test_interactions, \n",
    "        item_features=item_features).mean()\n",
    "print(auc_train)\n",
    "print(auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is 0.09 which is acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038148835\n",
      "0.009532729\n"
     ]
    }
   ],
   "source": [
    "train_precision = precision_at_k(best_model, train_interactions, k=10,item_features=item_features).mean()\n",
    "test_precision = precision_at_k(best_model, test_interactions, k=10,item_features=item_features).mean()\n",
    "\n",
    "print(train_precision)\n",
    "print(test_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0820300077883452\n",
      "0.03666967454034619\n"
     ]
    }
   ],
   "source": [
    "train_recall = recall_at_k(best_model, train_interactions, k=10,item_features=item_features).mean()\n",
    "test_recall = recall_at_k(best_model, test_interactions, k=10,item_features=item_features).mean()\n",
    "\n",
    "print(train_recall)\n",
    "print(test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Hybrid_new2.pickle', 'wb') as fle:\n",
    "    pickle.dump(best_model, fle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Hybrid_new2.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    model_from_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84072757\n"
     ]
    }
   ],
   "source": [
    "score_from_pkl = auc_score( \n",
    "        model_from_pickle, interactions, \n",
    "        item_features=item_features).mean()\n",
    "print(score_from_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `recsys` predefined functions from the Recommender System cookbook to get some recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Cleaned_Data/book_user_explicit_rating_cleaned.csv',encoding='UTF-8')\n",
    "df = df.drop(columns=['index'])\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.drop(columns=['Image_URL','ISBN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unique_ISBN</th>\n",
       "      <th>0002005018</th>\n",
       "      <th>0002251760</th>\n",
       "      <th>0002550563</th>\n",
       "      <th>0003300277</th>\n",
       "      <th>000617616X</th>\n",
       "      <th>0006471641</th>\n",
       "      <th>0006480608</th>\n",
       "      <th>0006492347</th>\n",
       "      <th>0006551971</th>\n",
       "      <th>0006742939</th>\n",
       "      <th>...</th>\n",
       "      <th>9580464162</th>\n",
       "      <th>958704049X</th>\n",
       "      <th>9681500555</th>\n",
       "      <th>9681500830</th>\n",
       "      <th>9681500954</th>\n",
       "      <th>9684068573</th>\n",
       "      <th>9722105248</th>\n",
       "      <th>9726101794</th>\n",
       "      <th>9871138148</th>\n",
       "      <th>B00009ANY9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Unique_ISBN  0002005018  0002251760  0002550563  0003300277  000617616X  \\\n",
       "User_ID                                                                   \n",
       "8                   5.0         0.0         0.0         0.0         0.0   \n",
       "17                  0.0         0.0         0.0         0.0         0.0   \n",
       "44                  0.0         0.0         0.0         0.0         0.0   \n",
       "53                  0.0         0.0         0.0         0.0         0.0   \n",
       "69                  0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "Unique_ISBN  0006471641  0006480608  0006492347  0006551971  0006742939  ...  \\\n",
       "User_ID                                                                  ...   \n",
       "8                   0.0         0.0         0.0         0.0         0.0  ...   \n",
       "17                  0.0         0.0         0.0         0.0         0.0  ...   \n",
       "44                  0.0         0.0         0.0         0.0         0.0  ...   \n",
       "53                  0.0         0.0         0.0         0.0         0.0  ...   \n",
       "69                  0.0         0.0         0.0         0.0         0.0  ...   \n",
       "\n",
       "Unique_ISBN  9580464162  958704049X  9681500555  9681500830  9681500954  \\\n",
       "User_ID                                                                   \n",
       "8                   0.0         0.0         0.0         0.0         0.0   \n",
       "17                  0.0         0.0         0.0         0.0         0.0   \n",
       "44                  0.0         0.0         0.0         0.0         0.0   \n",
       "53                  0.0         0.0         0.0         0.0         0.0   \n",
       "69                  0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "Unique_ISBN  9684068573  9722105248  9726101794  9871138148  B00009ANY9  \n",
       "User_ID                                                                  \n",
       "8                   0.0         0.0         0.0         0.0         0.0  \n",
       "17                  0.0         0.0         0.0         0.0         0.0  \n",
       "44                  0.0         0.0         0.0         0.0         0.0  \n",
       "53                  0.0         0.0         0.0         0.0         0.0  \n",
       "69                  0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 13607 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to create an interaction matrix dataframe from transactional type interactions\n",
    "interactions_mtx = df.groupby(['User_ID', 'Unique_ISBN'])['Book_Rating'].sum().unstack().reset_index().fillna(0).set_index('User_ID')\n",
    "interactions_mtx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17511, 13607)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "_books = df.drop(columns=['User_ID','Age','Age_Range','Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a user dictionary based on their index and number in interaction dataset\n",
    "user_id = list(interactions_mtx.index)\n",
    "user_dict = {}\n",
    "counter = 0 \n",
    "for i in user_id:\n",
    "    user_dict[i] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create an item dictionary based on their item_id and item name\n",
    "_books = _books.reset_index()\n",
    "item_dict ={}\n",
    "for i in range(_books.shape[0]):\n",
    "    item_dict[(_books.loc[i,'Unique_ISBN'])] = _books.loc[i,'Book_Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation_user(model, interactions, user_id, user_dict, \n",
    "                               item_dict,threshold = 0,nrec_items = 10, show = True):\n",
    "    '''\n",
    "    Function to produce user recommendations\n",
    "    Required Input - \n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "        - user_id = user ID for which we need to generate recommendation\n",
    "        - user_dict = Dictionary type input containing interaction_index as key and user_id as value\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - threshold = value above which the rating is favorable in new interaction matrix\n",
    "        - nrec_items = Number of output recommendation needed\n",
    "    Expected Output - \n",
    "        - Prints list of items the given user has already bought\n",
    "        - Prints list of N recommended items  which user hopefully will be interested in\n",
    "    '''\n",
    "    n_users, n_items = interactions.shape\n",
    "    user_x = user_dict[user_id]\n",
    "    scores = pd.Series(model.predict(user_x,np.arange(n_items)))\n",
    "    scores.index = interactions.columns\n",
    "    scores = list(pd.Series(scores.sort_values(ascending=False).index))\n",
    "    \n",
    "    known_items = list(pd.Series(interactions.loc[user_id,:] \\\n",
    "                                 [interactions.loc[user_id,:] > threshold].index) \\\n",
    "                                .sort_values(ascending=False))\n",
    "    #print(known_items)\n",
    "    \n",
    "    scores = [x for x in scores if x not in known_items]\n",
    "    return_score_list = scores[0:nrec_items]\n",
    "    known_items = list(pd.Series(known_items).apply(lambda x: item_dict[x]))\n",
    "    scores = list(pd.Series(return_score_list).apply(lambda x: item_dict[x]))\n",
    "    if show == True:\n",
    "        print(\"Known Likes:\")\n",
    "        counter = 1\n",
    "        for i in known_items:\n",
    "            #print(i)\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "\n",
    "        print(\"\\n Recommended Items:\")\n",
    "        counter = 1\n",
    "        for i in scores:\n",
    "            #print(i)\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "    return return_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Likes:\n",
      "1- WEST OF DODGE\n",
      "2- VICE\n",
      "3- MURDER AT THE KENNEDY CENTER (CAPITAL CRIME MYSTERIES)\n",
      "4- DIVINE SECRETS OF THE YA-YA SISTERHOOD: A NOVEL\n",
      "\n",
      " Recommended Items:\n",
      "1- GIRLFRIEND IN A COMA\n",
      "2- A THIEF OF TIME: A NOVEL (HARPER NOVEL OF SUSPENSE)\n",
      "3- TRIXIE BELDEN AND THE GATEHOUSE MYSTERY (GATEHOUSE MYSTERY)\n",
      "4- PATRON SAINT OF LIARS : A NOVEL\n",
      "5- ICE STATION\n",
      "6- LINDA GOODMAN'S LOVE SIGNS : A NEW APPROACH TO THE HUMAN HEART\n",
      "7- VITTORIO THE VAMPIRE: NEW TALES OF THE VAMPIRES\n",
      "8- MONSTROUS REGIMENT (PRATCHETT, TERRY)\n",
      "9- NO ONE WRITES TO THE COLONEL\n",
      "10- MEN, WOMEN AND RELATIONSHIPS\n"
     ]
    }
   ],
   "source": [
    "rec_list = sample_recommendation_user(model = model_from_pickle, \n",
    "                                      interactions = interactions_mtx, \n",
    "                                      user_id = 900, \n",
    "                                      user_dict = user_dict,\n",
    "                                      item_dict = item_dict, \n",
    "                                      threshold = 4,\n",
    "                                      nrec_items = 10,\n",
    "                                      show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation_item(model,interactions,item_id,user_dict,item_dict,number_of_user):\n",
    "    '''\n",
    "    Funnction to produce a list of top N interested users for a given item\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "        - item_id = item ID for which we need to generate recommended users\n",
    "        - user_dict =  Dictionary type input containing interaction_index as key and user_id as value\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - number_of_user = Number of users needed as an output\n",
    "    Expected Output -\n",
    "        - user_list = List of recommended users \n",
    "    '''\n",
    "    n_users, n_items = interactions.shape\n",
    "    x = np.array(interactions.columns)\n",
    "    scores = pd.Series(model.predict(np.arange(n_users), np.repeat(x.searchsorted(item_id),n_users)))\n",
    "    user_list = list(interactions.index[scores.sort_values(ascending=False).head(number_of_user).index])\n",
    "    return user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128601, 18095, 136117, 80954, 36441, 69684, 134630, 47929, 167562, 132572]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_recommendation_item(model = model_from_pickle,\n",
    "                           interactions = interactions_mtx,\n",
    "                           item_id = '0385504209',\n",
    "                           user_dict = user_dict,\n",
    "                           item_dict = item_dict,\n",
    "                           number_of_user = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Factorization Machine for basic CF to get item-item recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fab1a6d1a60>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to run matrix-factorization algorithm\n",
    "x = sparse.csr_matrix(interactions_mtx.values)\n",
    "model_new = LightFM(loss='warp',learning_rate=0.01824398527330847,no_components=45)\n",
    "model_new.fit(x,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_emdedding_distance_matrix(model,interactions):\n",
    "    '''\n",
    "    Function to create item-item distance embedding matrix\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "    Expected Output -\n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "    '''\n",
    "    df_item_norm_sparse = sparse.csr_matrix(model.item_embeddings)\n",
    "    similarities = cosine_similarity(df_item_norm_sparse)\n",
    "    item_emdedding_distance_matrix = pd.DataFrame(similarities)\n",
    "    item_emdedding_distance_matrix.columns = interactions.columns\n",
    "    item_emdedding_distance_matrix.index = interactions.columns\n",
    "    return item_emdedding_distance_matrix\n",
    "\n",
    "## Creating item-item distance matrix\n",
    "item_item_dist = create_item_emdedding_distance_matrix(model = model_new,\n",
    "                                                       interactions = interactions_mtx)\n",
    "## Checking item embedding distance matrix\n",
    "#item_item_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item of interest :THE DA VINCI CODE\n",
      "Item similar to the above item:\n",
      "1- ANGELS &AMP; DEMONS\n",
      "2- THE DOGS OF BABEL (TODAY SHOW BOOK CLUB #12)\n",
      "3- THE LOVELY BONES: A NOVEL\n",
      "4- BLEACHERS\n",
      "5- DIGITAL FORTRESS : A THRILLER\n",
      "6- THE SECRET LIFE OF BEES\n",
      "7- I DO (BUT I DON'T)\n",
      "8- THE HOURS: A NOVEL\n",
      "9- THE FIVE PEOPLE YOU MEET IN HEAVEN\n",
      "10- NICE\n"
     ]
    }
   ],
   "source": [
    "def item_item_recommendation(item_emdedding_distance_matrix, item_id, \n",
    "                             item_dict, n_items = 10, show = True):\n",
    "    '''\n",
    "    Function to create item-item recommendation\n",
    "    Required Input - \n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "        - item_id  = item ID for which we need to generate recommended items\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - n_items = Number of items needed as an output\n",
    "    Expected Output -\n",
    "        - recommended_items = List of recommended items\n",
    "    '''\n",
    "    recommended_items = list(pd.Series(item_emdedding_distance_matrix.loc[item_id,:]. \\\n",
    "                                  sort_values(ascending = False).head(n_items+1). \\\n",
    "                                  index[1:n_items+1]))\n",
    "    if show == True:\n",
    "        print(\"Item of interest :{0}\".format(item_dict[item_id]))\n",
    "        print(\"Item similar to the above item:\")\n",
    "        counter = 1\n",
    "        for i in recommended_items:\n",
    "            print(str(counter) + '- ' +  item_dict[i])\n",
    "            counter+=1\n",
    "    return recommended_items\n",
    "\n",
    "## Calling 5 recommended items for item id \n",
    "rec_list = item_item_recommendation(item_emdedding_distance_matrix = item_item_dist,\n",
    "                                    item_id = '0385504209',\n",
    "                                    item_dict = item_dict,\n",
    "                                    n_items = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
