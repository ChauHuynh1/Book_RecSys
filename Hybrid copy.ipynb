{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import tensorflow.compat.v1 as tf\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k, reciprocal_rank\n",
    "from lightfm import cross_validation\n",
    "import csv\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return csv.DictReader(\n",
    "            (x for x in open('Data/Cleaned_Data/book_user_explicit_rating_cleaned.csv','r'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.fit(users=(x['User_ID'] for x in get_data()),\n",
    "            items=(x['Unique_ISBN'] for x in get_data()),\n",
    "            item_features=(x['Book_Title'] for x in get_data()),\n",
    "            user_features=(x['Age_Range'] for x in get_data())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 17511, num_items 13607.\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('Num users: {}, num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions, weights) = dataset.build_interactions(((x['User_ID'], x['Unique_ISBN'])\n",
    "                                                      for x in get_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<17511x13607 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 151324 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<13607x27215 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 27215 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "item_features = dataset.build_item_features(((x['Unique_ISBN'], [x['Book_Title']])\n",
    "                                              for x in get_data()))\n",
    "print(repr(item_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<17511x17516 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 35022 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "user_features = dataset.build_user_features(((x['User_ID'], [x['Age_Range']])\n",
    "                                              for x in get_data()))\n",
    "print(repr(user_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions, test_interactions = cross_validation.random_train_test_split(interactions, random_state=np.random.RandomState(seed=11232))\n",
    "\n",
    "train_weights, test_weights = cross_validation.random_train_test_split(weights, random_state=np.random.RandomState(seed=11232))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def sample_hyperparameters():\n",
    "    \"\"\"\n",
    "    Yield possible hyperparameter choices.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        yield {\n",
    "            \"no_components\": np.random.randint(16, 64),\n",
    "            \"loss\": np.random.choice([\"warp\"]),\n",
    "            \"learning_rate\": np.random.exponential(0.05),\n",
    "            \"num_epochs\": np.random.randint(5, 50),\n",
    "            \"random_state\":np.random.RandomState(seed=11232)\n",
    "        }\n",
    "\n",
    "\n",
    "def random_search(train, test, num_samples=10):\n",
    "    \"\"\"\n",
    "    Sample random hyperparameters, fit a LightFM model, and evaluate it\n",
    "    on the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    train: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Training data.\n",
    "    test: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Test data.\n",
    "    num_samples: int, optional\n",
    "        Number of hyperparameter choices to evaluate.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    generator of (auc_score, hyperparameter dict, fitted model)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for hyperparams in itertools.islice(sample_hyperparameters(), num_samples):\n",
    "        num_epochs = hyperparams.pop(\"num_epochs\")\n",
    "\n",
    "        model_tune = LightFM(**hyperparams)\n",
    "        model_tune.fit(interactions=train, epochs=num_epochs, item_features=item_features, user_features=user_features,sample_weight=train_weights)\n",
    "\n",
    "        score = auc_score(model_tune, train, item_features=item_features, user_features=user_features).mean()\n",
    "        auc_test = auc_score(model_tune, test, item_features=item_features, user_features=user_features).mean()\n",
    "\n",
    "        hyperparams[\"num_epochs\"] = num_epochs\n",
    "\n",
    "        yield (score, auc_test, hyperparams, model_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.933440625667572 at {'no_components': 57, 'loss': 'warp', 'learning_rate': 0.08746559082746974, 'random_state': RandomState(MT19937) at 0x7F83A1F98640, 'num_epochs': 25}\n",
      "Best test 0.7193669676780701 at {'no_components': 57, 'loss': 'warp', 'learning_rate': 0.08746559082746974, 'random_state': RandomState(MT19937) at 0x7F83A1F98640, 'num_epochs': 25}\n"
     ]
    }
   ],
   "source": [
    "(score, auc_test, hyperparams, model_tune) = max(random_search(train_interactions, test_interactions), key=lambda x: x[0])\n",
    "\n",
    "print(\"Best score {} at {}\".format(score, hyperparams))\n",
    "print(\"Best test {} at {}\".format(auc_test, hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LightFM(loss='warp',learning_rate=0.07855246734493881,no_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:01<00:00,  2.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f83a297c730>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(\n",
    "    interactions=train_interactions,\n",
    "    item_features=item_features,\n",
    "    user_features=user_features, sample_weight=train_weights,\n",
    "    epochs=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8075902\n",
      "0.7151767\n"
     ]
    }
   ],
   "source": [
    "auc_train = auc_score( \n",
    "        best_model, train_interactions, \n",
    "        item_features=item_features, \n",
    "        user_features=user_features).mean()\n",
    "auc_test = auc_score( \n",
    "        best_model, test_interactions, \n",
    "        item_features=item_features, \n",
    "        user_features=user_features).mean()\n",
    "print(auc_train)\n",
    "print(auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7878459\n"
     ]
    }
   ],
   "source": [
    "score = auc_score( \n",
    "        best_model, interactions, \n",
    "        item_features=item_features, \n",
    "        user_features=user_features).mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01402742\n",
      "0.0052740537\n"
     ]
    }
   ],
   "source": [
    "train_precision = precision_at_k(best_model, train_interactions, k=10,item_features=item_features,user_features=user_features).mean()\n",
    "test_precision = precision_at_k(best_model, test_interactions, k=10,item_features=item_features,user_features=user_features).mean()\n",
    "\n",
    "print(train_precision)\n",
    "print(test_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Hybrid_new.pickle', 'wb') as fle:\n",
    "    pickle.dump(best_model, fle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Hybrid_new.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    model_from_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_from_pkl = auc_score( \n",
    "        model_from_pickle, interactions, \n",
    "        item_features=item_features, \n",
    "        user_features=user_features).mean()\n",
    "print(score_from_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Cleaned_Data/book_user_explicit_rating_cleaned.csv',encoding='UTF-8')\n",
    "df = df.drop(columns=['index'])\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.drop(columns=['Image_URL','ISBN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17511, 13607)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to create an interaction matrix dataframe from transactional type interactions\n",
    "interactions_mtx = df.groupby(['User_ID', 'Unique_ISBN'])['Book_Rating'].sum().unstack().reset_index().fillna(0).set_index('User_ID')\n",
    "    \n",
    "interactions_mtx.head()\n",
    "interactions_mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_books = df.drop(columns=['User_ID','Age','Age_Range','Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a user dictionary based on their index and number in interaction dataset\n",
    "user_id = list(interactions_mtx.index)\n",
    "user_dict = {}\n",
    "counter = 0 \n",
    "for i in user_id:\n",
    "    user_dict[i] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create an item dictionary based on their item_id and item name\n",
    "_books = _books.reset_index()\n",
    "item_dict ={}\n",
    "for i in range(_books.shape[0]):\n",
    "    item_dict[(_books.loc[i,'Unique_ISBN'])] = _books.loc[i,'Book_Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f83a2bb7af0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to run matrix-factorization algorithm\n",
    "x = sparse.csr_matrix(interactions_mtx.values)\n",
    "model_new = LightFM(loss='warp',learning_rate=0.07855246734493881,no_components=30)\n",
    "model_new.fit(x,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5019348\n",
      "0.5024585\n"
     ]
    }
   ],
   "source": [
    "auc_train_new = auc_score( \n",
    "        model_new, train_interactions).mean()\n",
    "auc_test_new = auc_score( \n",
    "        model_new, test_interactions).mean()\n",
    "print(auc_train_new)\n",
    "print(auc_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation_user(model, interactions, user_id, user_dict, \n",
    "                               item_dict,threshold = 0,nrec_items = 10, show = True):\n",
    "    '''\n",
    "    Function to produce user recommendations\n",
    "    Required Input - \n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "        - user_id = user ID for which we need to generate recommendation\n",
    "        - user_dict = Dictionary type input containing interaction_index as key and user_id as value\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - threshold = value above which the rating is favorable in new interaction matrix\n",
    "        - nrec_items = Number of output recommendation needed\n",
    "    Expected Output - \n",
    "        - Prints list of items the given user has already bought\n",
    "        - Prints list of N recommended items  which user hopefully will be interested in\n",
    "    '''\n",
    "    n_users, n_items = interactions.shape\n",
    "    user_x = user_dict[user_id]\n",
    "    scores = pd.Series(model.predict(user_x,np.arange(n_items)))\n",
    "    scores.index = interactions.columns\n",
    "    scores = list(pd.Series(scores.sort_values(ascending=False).index))\n",
    "    \n",
    "    known_items = list(pd.Series(interactions.loc[user_id,:] \\\n",
    "                                 [interactions.loc[user_id,:] > threshold].index) \\\n",
    "                                .sort_values(ascending=False))\n",
    "    #print(known_items)\n",
    "    \n",
    "    scores = [x for x in scores if x not in known_items]\n",
    "    return_score_list = scores[0:nrec_items]\n",
    "    known_items = list(pd.Series(known_items).apply(lambda x: item_dict[x]))\n",
    "    scores = list(pd.Series(return_score_list).apply(lambda x: item_dict[x]))\n",
    "    if show == True:\n",
    "        print(\"Known Likes:\")\n",
    "        counter = 1\n",
    "        for i in known_items:\n",
    "            #print(i)\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "\n",
    "        print(\"\\n Recommended Items:\")\n",
    "        counter = 1\n",
    "        for i in scores:\n",
    "            #print(i)\n",
    "            print(str(counter) + '- ' + i)\n",
    "            counter+=1\n",
    "    return return_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Likes:\n",
      "1- WEST OF DODGE\n",
      "2- VICE\n",
      "3- MURDER AT THE KENNEDY CENTER (CAPITAL CRIME MYSTERIES)\n",
      "4- DIVINE SECRETS OF THE YA-YA SISTERHOOD: A NOVEL\n",
      "\n",
      " Recommended Items:\n",
      "1- DER STRAND\n",
      "2- BLACK AND BLUE (BLACK &AMP; BLUE)\n",
      "3- A LITTLE LOOK-SEE:  MUTTS 6\n",
      "4- THE SUMMER TREE (THE FIONAVAR TAPESTRY, BOOK 1)\n",
      "5- LIVES OF THE MONSTER DOGS\n",
      "6- COMPELLING EVIDENCE\n",
      "7- COFFEE &AMP; KUNG FU\n",
      "8- HALF ASLEEP IN FROG PAJAMAS\n",
      "9- THE PILGRIMAGE\n",
      "10- THE FOREST LORD\n"
     ]
    }
   ],
   "source": [
    "rec_list = sample_recommendation_user(model = model_from_pickle, \n",
    "                                      interactions = interactions_mtx, \n",
    "                                      user_id = 900, \n",
    "                                      user_dict = user_dict,\n",
    "                                      item_dict = item_dict, \n",
    "                                      threshold = 4,\n",
    "                                      nrec_items = 10,\n",
    "                                      show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation_item(model,interactions,item_id,user_dict,item_dict,number_of_user):\n",
    "    '''\n",
    "    Funnction to produce a list of top N interested users for a given item\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "        - item_id = item ID for which we need to generate recommended users\n",
    "        - user_dict =  Dictionary type input containing interaction_index as key and user_id as value\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - number_of_user = Number of users needed as an output\n",
    "    Expected Output -\n",
    "        - user_list = List of recommended users \n",
    "    '''\n",
    "    n_users, n_items = interactions.shape\n",
    "    x = np.array(interactions.columns)\n",
    "    scores = pd.Series(model.predict(np.arange(n_users), np.repeat(x.searchsorted(item_id),n_users)))\n",
    "    user_list = list(interactions.index[scores.sort_values(ascending=False).head(number_of_user).index])\n",
    "    return user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58869, 176667, 141888, 257927, 166828, 64589, 204804, 206774, 112765, 28763]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_recommendation_item(model = model_from_pickle,\n",
    "                           interactions = interactions_mtx,\n",
    "                           item_id = '0385504209',\n",
    "                           user_dict = user_dict,\n",
    "                           item_dict = item_dict,\n",
    "                           number_of_user = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_emdedding_distance_matrix(model,interactions):\n",
    "    '''\n",
    "    Function to create item-item distance embedding matrix\n",
    "    Required Input -\n",
    "        - model = Trained matrix factorization model\n",
    "        - interactions = dataset used for training the model\n",
    "    Expected Output -\n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "    '''\n",
    "    df_item_norm_sparse = sparse.csr_matrix(model.item_embeddings)\n",
    "    similarities = cosine_similarity(df_item_norm_sparse)\n",
    "    item_emdedding_distance_matrix = pd.DataFrame(similarities)\n",
    "    item_emdedding_distance_matrix.columns = interactions.columns\n",
    "    item_emdedding_distance_matrix.index = interactions.columns\n",
    "    return item_emdedding_distance_matrix\n",
    "\n",
    "## Creating item-item distance matrix\n",
    "item_item_dist = create_item_emdedding_distance_matrix(model = model_new,\n",
    "                                                       interactions = interactions_mtx)\n",
    "## Checking item embedding distance matrix\n",
    "#item_item_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item of interest :THE DA VINCI CODE\n",
      "Item similar to the above item:\n",
      "1- THE BIRTH OF VENUS\n",
      "2- ANGELS &AMP; DEMONS\n",
      "3- A LOST LADY (VINTAGE CLASSICS)\n",
      "4- THE SAVING GRACES : A NOVEL\n",
      "5- THE PILOT'S WIFE : A NOVEL TAG: AUTHOR OF THE WEIGHT OF WATER (OPRAH'S BOOK CLUB (HARDCOVER))\n",
      "6- SHEPHERDS ABIDING\n",
      "7- CHEAPER BY THE DOZEN (PERENNIAL CLASSICS)\n",
      "8- AMBULANCE GIRL: HOW I SAVED MYSELF BY BECOMING AN EMT\n",
      "9- A THOUSAND DAYS IN VENICE: AN UNEXPECTED ROMANCE (BALLANTINE READER'S CIRCLE)\n",
      "10- AMERICAN FUJI\n"
     ]
    }
   ],
   "source": [
    "def item_item_recommendation(item_emdedding_distance_matrix, item_id, \n",
    "                             item_dict, n_items = 10, show = True):\n",
    "    '''\n",
    "    Function to create item-item recommendation\n",
    "    Required Input - \n",
    "        - item_emdedding_distance_matrix = Pandas dataframe containing cosine distance matrix b/w items\n",
    "        - item_id  = item ID for which we need to generate recommended items\n",
    "        - item_dict = Dictionary type input containing item_id as key and item_name as value\n",
    "        - n_items = Number of items needed as an output\n",
    "    Expected Output -\n",
    "        - recommended_items = List of recommended items\n",
    "    '''\n",
    "    recommended_items = list(pd.Series(item_emdedding_distance_matrix.loc[item_id,:]. \\\n",
    "                                  sort_values(ascending = False).head(n_items+1). \\\n",
    "                                  index[1:n_items+1]))\n",
    "    if show == True:\n",
    "        print(\"Item of interest :{0}\".format(item_dict[item_id]))\n",
    "        print(\"Item similar to the above item:\")\n",
    "        counter = 1\n",
    "        for i in recommended_items:\n",
    "            print(str(counter) + '- ' +  item_dict[i])\n",
    "            counter+=1\n",
    "    return recommended_items\n",
    "\n",
    "## Calling 5 recommended items for item id \n",
    "rec_list = item_item_recommendation(item_emdedding_distance_matrix = item_item_dist,\n",
    "                                    item_id = '0385504209',\n",
    "                                    item_dict = item_dict,\n",
    "                                    n_items = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
