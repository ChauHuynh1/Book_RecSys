{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import surprise\n",
    "from surprise import KNNBaseline, SVDpp\n",
    "from surprise.model_selection import GridSearchCV, cross_validate\n",
    "from surprise import Dataset, Reader\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import math\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Cleaned_Data/book_user_explicit_rating_cleaned.csv',encoding='UTF-8')\n",
    "df = df.drop(columns=['index'])\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.drop(columns=['Image_URL','ISBN'])\n",
    "df = df.sample(n=8000, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelenc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df,param):\n",
    "    df[param] = labelenc.fit_transform(df[param].values)\n",
    "    df[param] = df[param].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding(df, 'User_ID')\n",
    "label_encoding(df, 'Unique_ISBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_data = df[['User_ID','Unique_ISBN','Book_Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of users: 4424\n",
      "num of books: 6809\n"
     ]
    }
   ],
   "source": [
    "print ('num of users:',df['User_ID'].nunique())\n",
    "print ('num of books:',df['Unique_ISBN'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = np.array(enc_data['User_ID'].tolist())\n",
    "book_ids = np.array(enc_data['Unique_ISBN'].tolist())\n",
    "user_ratings = np.array(enc_data[\"Book_Rating\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "n_book = 6809\n",
    "n_user = 4424\n",
    "embedding_size = 30\n",
    "\n",
    "lr = 0.0001\n",
    "reg = 0.001\n",
    "\n",
    "with graph.as_default():\n",
    "    user = tf.placeholder(tf.int32, name=\"User_ID\") \n",
    "    book = tf.placeholder(tf.int32, name=\"Unique_ISBN\") \n",
    "    rating = tf.placeholder(tf.float32, name=\"Book_Rating\") \n",
    "\n",
    "    book_embedding = tf.Variable(tf.truncated_normal([n_book, embedding_size], stddev=0.02, mean=0.) ,name=\"Book_Embedding\")\n",
    "    user_embedding = tf.Variable(tf.truncated_normal([n_user, embedding_size], stddev=0.02, mean=0.) ,name=\"User_Embedding\")\n",
    "    \n",
    "    book_bias_embedding = tf.Variable(tf.truncated_normal([n_book], stddev=0.02, mean=0.) ,name=\"book_bias_embedding\")\n",
    "    user_bias_embedding = tf.Variable(tf.truncated_normal([n_user], stddev=0.02, mean=0.) ,name=\"user_bias_embedding\")\n",
    "    \n",
    "    \n",
    "    global_bias = tf.Variable(tf.truncated_normal([], stddev=0.02, mean=0.) ,name=\"global_bias\")\n",
    "    \n",
    "    u = tf.nn.embedding_lookup(user_embedding, user)\n",
    "    m = tf.nn.embedding_lookup(book_embedding, book)\n",
    "    \n",
    "    u_bias = tf.nn.embedding_lookup(user_bias_embedding, user)\n",
    "    m_bias = tf.nn.embedding_lookup(book_bias_embedding, book)\n",
    "    \n",
    "\n",
    "    predicted_rating = tf.reduce_sum(tf.multiply(u, m), 1) + u_bias + m_bias + global_bias\n",
    "\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square(predicted_rating - rating))) # RMSE\n",
    "    cost = tf.nn.l2_loss(predicted_rating - rating)\n",
    "    regularization = reg * (tf.nn.l2_loss(book_embedding) + tf.nn.l2_loss(user_embedding)\n",
    "                            + tf.nn.l2_loss(book_bias_embedding) + tf.nn.l2_loss(user_bias_embedding))\n",
    "    \n",
    "    loss = cost + regularization\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 8.101506\n",
      "RMSE 7.703277\n",
      "RMSE 7.306424\n",
      "RMSE 6.9110403\n",
      "RMSE 6.517368\n",
      "RMSE 6.125718\n",
      "RMSE 5.7364936\n",
      "RMSE 5.3501844\n",
      "RMSE 4.967443\n",
      "RMSE 4.589114\n",
      "RMSE 4.2163067\n",
      "RMSE 3.8505027\n",
      "RMSE 3.4936934\n",
      "RMSE 3.1485133\n",
      "RMSE 2.8185418\n",
      "RMSE 2.5084975\n",
      "RMSE 2.2236516\n",
      "RMSE 1.9699754\n",
      "RMSE 1.752543\n",
      "RMSE 1.5734547\n",
      "RMSE 1.4313893\n",
      "RMSE 1.3215111\n",
      "RMSE 1.2387948\n",
      "RMSE 1.1773349\n",
      "RMSE 1.1319624\n",
      "RMSE 1.0984858\n",
      "RMSE 1.0737143\n",
      "RMSE 1.055301\n",
      "RMSE 1.0415324\n",
      "RMSE 1.0311364\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "n_epoch = 50\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for _ in range(n_epoch):\n",
    "        for start in range(0, user_ratings.shape[0] - batch_size, batch_size):\n",
    "            end = start + batch_size\n",
    "            _, cost_value = sess.run([optimizer, rmse], feed_dict={user: user_ids[start:end],\n",
    "                                                  book: book_ids[start: end],\n",
    "                                                  rating: user_ratings[start: end]})\n",
    "\n",
    "        print (\"RMSE\", cost_value)\n",
    "    embeddings = book_embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = enc_data.sample(n=8000, replace=False, random_state=1)\n",
    "R = pd.pivot_table(df_rating, values='Book_Rating', index=['User_ID'],columns=['Unique_ISBN'], fill_value=0).to_numpy()\n",
    "print ('{0}x{1} user by user matrix'.format(*R.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating2 = enc_data.sample(n=8000, replace=False, random_state=1)\n",
    "df_feature_frame = pd.pivot_table(df_rating2, values='Book_Rating', index=['Unique_ISBN'],columns=['User_ID'], fill_value=0)\n",
    "df_feature = pd.pivot_table(df_rating2, values='Book_Rating', index=['Unique_ISBN'],columns=['User_ID'], fill_value=0).to_numpy()\n",
    "\n",
    "print ('{0}x{1} user by book matrix'.format(*df_feature.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train, test split\n",
    "train_user = R[:3539, :885]\n",
    "test_user = R[3539:, 885:]\n",
    "train_book = df_feature[:5448, :1361]\n",
    "test_book = df_feature[5448:, 1361:]\n",
    "\n",
    "book_svd = TruncatedSVD(n_components=10)\n",
    "book_features = book_svd.fit_transform(train_book)\n",
    "\n",
    "print (\"book_features.shape = {0}\".format(book_features.shape))\n",
    "\n",
    "\n",
    "user_svd = TruncatedSVD(n_components=10)\n",
    "user_features = user_svd.fit_transform(train_user)\n",
    "\n",
    "print (\"user_features.shape = {0}\".format(user_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_avg = df.groupby(['Unique_ISBN'])['Book_Rating'].mean().reset_index()\n",
    "df_rating_avg['Book_Rating'] = df_rating_avg['Book_Rating'].round(1)\n",
    "df_rating_avg['Unique_ISBN'] = df_rating_avg['Unique_ISBN'].astype(str)\n",
    "df_rating_ = df_rating_avg.set_index('Unique_ISBN')\n",
    "df_train = pd.merge(df_feature_frame, df_rating_, left_index=True, right_index=True, how='right')\n",
    "df_train.dropna(inplace=True)\n",
    "targets = np.array(df_train.Book_Rating)\n",
    "data = np.array(df_train.drop(['rating'], axis = 1))\n",
    "\n",
    "print (\"targets.shape = {0}\".format(targets.shape))\n",
    "print (\"data.shape = {0}\".format(data.shape))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
